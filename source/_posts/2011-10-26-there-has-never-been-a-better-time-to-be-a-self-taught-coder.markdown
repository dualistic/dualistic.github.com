---
layout: post
title: "There Has Never Been a Better Time to Be a Self-taught Coder"
date: 2011-10-26 21:09
comments: true
categories: [educause, computer science, education]
---
I posted this as a response to a [blog post](http://www.catherynnemvalente.com/2011/10/post-apocalyptic-undergraduate-zombies/), and I thought it might be more generally appreciated.  It was in response to a short quote in the post where she was wondering which degrees might be worth the astronomical cost of tuition, "Computer Science, I guess..."

I hate to say it but to be honest, there has never been a better time to *not* be in the process of getting a computer science degree.  I work in academia, so this is a really tough thing to admit, but I think it's true.  It's not just the spiraling cost of education, and the cost/benefit analysis of tuition. The whole situation is changing. 
<!--more--> 
The biggest game-changer, I think, is that there is a ridiculous amount of opportunity out there for free.  It used to be that you had to go to university for the opportunity to get practice doing the work.  This isn't the case anymore. Employers are still mostly interested in examples of your work (basically, a portfolio of code), but with open source being what it is, the world is overflowing with public projects to work on.  If you spent four years working food service and spending your off time coding on open source projects (with the same amount of time that you would have spent schooling), you would end up better off.  Probably wildly better off.  Many CS grads enter the job market with nothing but credentials and examples of canned homework projects.  Sure, they know the basics of algorithms, but that is just a small part of what software engineering is.

Self-taught coders are often preferred over graduates because they have demonstrated at least one critical skill: the ability to independently find solutions to get things done.  If they have worked on an active open source project, then they have another critical coveted skill: the ability to collaboratively work on software projects with other developers. 

And to add to that, MIT open courseware is freely available, a curious student has access to world-class educational tools if they need it. More and more institutions are making their materials available, and Khan Academy just released its first set of computer science training classes for free.  The entire landscape is changing.

During the recent EDUCAUSE conference, I heard this small-but-growing group of self-taught students "edupunks".  The [presentation was posted online](http://www.educause.edu/E2011/Program/FS04?page=1#tabs--2) and I think it's worth a look if you are interested.

I think the future of education is changing.  I still think academia is important, but the focus needs to change.  I don't think that it will make sense to go to university for classes, but for hands-on training and research opportunities.  University is where mentors and students gather and work.  Live lectures are a waste of time, they should be just video.  In the classroom you should be having real-world work experiences with teachers and peers.  This transition will be painful and ugly, but I think it's inevitable; the current system isn't sustainable.  Learning is about practice and mentorship.  That's what tuition should buy you.